{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b6fa66-beeb-4fdf-8de1-0bf6c1f17339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MinBPE.TikToken\n",
    "import MinBPE.Codec\n",
    "import MinBPE.Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c35ca1-f3c3-4e0c-a29a-1000bd44cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v <- loadTikToken \"../example/cl100k_base.tiktoken\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3d8eeb-a98f-4d47-8319-2ca762597506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data.Map (Map, (!))\n",
    "import qualified Data.Map as Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec1cb0ee-0b79-47d3-bd89-67f90f812acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.size v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe5abd7-e803-445d-ac1c-98d17bb447db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = vocabToVector v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce85754-c4f5-4cf0-82b1-d5bb18a3fe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tiktoken is great!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decodeBS3 vv [83, 1609, 5963, 374, 2294, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b1454e-c0c8-44f6-a7ce-762906c2a2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"antidisestablishmentarianism\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decodeBS3 vv [519, 85342, 34500, 479, 8997, 2191]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deda012c-b3b3-422f-babd-24ae8775bc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "お誕生日おめでとう"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TIO.putStrLn $ decode v [33334, 45918, 243, 21990, 9080, 33334, 62004, 16556, 78699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e334090-2548-41cf-8f57-5250d0583356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qualified Data.Text.IO as TIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2ede61f-71ac-408a-b498-776a03ad909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI's large language models (sometimes referred to as GPT's) process text using tokens, which are common sequences of characters found in a set of text. The models learn to understand the statistical relationships between these tokens, and excel at producing the next token in a sequence of tokens.\n",
       "\n",
       "You can use the tool below to understand how a piece of text might be tokenized by a language model, and the total count of tokens in that piece of text.\n",
       "\n",
       "It's important to note that the exact tokenization process varies between models. Newer models like GPT-3.5 and GPT-4 use a different tokenizer than previous models, and will produce different tokens for the same input text."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TIO.putStrLn $ decode v [5109, 15836, 596, 3544, 4221, 4211, 320, 57753, 14183, 311, 439, 480, 2898, 596, 8, 1920, 1495, 1701, 11460, 11, 902, 527, 4279, 24630, 315, 5885, 1766, 304, 264, 743, 315, 1495, 13, 578, 4211, 4048, 311, 3619, 279, 29564, 12135, 1990, 1521, 11460, 11, 323, 25555, 520, 17843, 279, 1828, 4037, 304, 264, 8668, 315, 11460, 382, 2675, 649, 1005, 279, 5507, 3770, 311, 3619, 1268, 264, 6710, 315, 1495, 2643, 387, 4037, 1534, 555, 264, 4221, 1646, 11, 323, 279, 2860, 1797, 315, 11460, 304, 430, 6710, 315, 1495, 382, 2181, 596, 3062, 311, 5296, 430, 279, 4839, 4037, 2065, 1920, 35327, 1990, 4211, 13, 1561, 261, 4211, 1093, 480, 2898, 12, 18, 13, 20, 323, 480, 2898, 12, 19, 1005, 264, 2204, 47058, 1109, 3766, 4211, 11, 323, 690, 8356, 2204, 11460, 369, 279, 1890, 1988, 1495, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c08753-7a15-476e-b70f-1e7ff600dcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "mimetype": "text/x-haskell",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "9.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
